<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Direct Pitch Shift Processor Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f5f5f5;
      }
      .container {
        background: white;
        padding: 30px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }
      .controls {
        margin: 20px 0;
      }
      .control-group {
        margin: 15px 0;
      }
      label {
        display: block;
        margin-bottom: 5px;
        font-weight: bold;
      }
      input[type="range"] {
        width: 100%;
        margin: 10px 0;
      }
      input[type="number"] {
        width: 80px;
        padding: 5px;
        margin-left: 10px;
      }
      button {
        background-color: #007bff;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 16px;
        margin: 10px 5px;
      }
      button:hover {
        background-color: #0056b3;
      }
      button:disabled {
        background-color: #6c757d;
        cursor: not-allowed;
      }
      .status {
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
        background-color: #e9ecef;
      }
      .error {
        background-color: #f8d7da;
        color: #721c24;
      }
      .success {
        background-color: #d4edda;
        color: #155724;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>üéµ Direct Pitch Shift Processor Test</h1>
      <p>
        This page tests the new direct audio graph processing approach:
        <strong>Microphone ‚Üí AudioWorklet ‚Üí Speakers</strong>
      </p>

      <div class="controls">
        <button id="startBtn">üé§ Start Processing</button>
        <button id="stopBtn" disabled>‚èπÔ∏è Stop Processing</button>
      </div>

      <div id="status" class="status">Ready to start</div>

      <div class="controls">
        <div class="control-group">
          <label>Pitch Ratio (0.25 - 4.0)</label>
          <input
            type="range"
            id="pitchSlider"
            min="0.25"
            max="4.0"
            step="0.1"
            value="1.5"
          />
          <input
            type="number"
            id="pitchNumber"
            min="0.25"
            max="4.0"
            step="0.1"
            value="1.5"
          />
        </div>

        <div class="control-group">
          <label>Formant Ratio (0.25 - 4.0)</label>
          <input
            type="range"
            id="formantSlider"
            min="0.25"
            max="4.0"
            step="0.1"
            value="1.2"
          />
          <input
            type="number"
            id="formantNumber"
            min="0.25"
            max="4.0"
            step="0.1"
            value="1.2"
          />
        </div>

        <div class="control-group">
          <label>Dry/Wet Mix (0.0 - 1.0)</label>
          <input
            type="range"
            id="wetSlider"
            min="0.0"
            max="1.0"
            step="0.1"
            value="0.7"
          />
          <input
            type="number"
            id="wetNumber"
            min="0.0"
            max="1.0"
            step="0.1"
            value="0.7"
          />
        </div>
      </div>

      <div
        style="margin-top: 30px; padding-top: 20px; border-top: 1px solid #eee"
      >
        <h3>üìã Instructions:</h3>
        <ol>
          <li>Click "Start Processing" to begin</li>
          <li>Allow microphone access when prompted</li>
          <li>Speak into your microphone</li>
          <li>Adjust sliders in real-time to hear changes</li>
          <li>Click "Stop Processing" when done</li>
        </ol>
      </div>
    </div>

    <script>
      let audioContext = null;
      let micSource = null;
      let workletNode = null;
      let mediaStream = null;
      let isProcessing = false;

      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const status = document.getElementById("status");

      // Parameter controls
      const pitchSlider = document.getElementById("pitchSlider");
      const pitchNumber = document.getElementById("pitchNumber");
      const formantSlider = document.getElementById("formantSlider");
      const formantNumber = document.getElementById("formantNumber");
      const wetSlider = document.getElementById("wetSlider");
      const wetNumber = document.getElementById("wetNumber");

      // Sync sliders and number inputs
      function syncControls(slider, number) {
        slider.addEventListener("input", () => {
          number.value = slider.value;
          updateProcessorConfig();
        });
        number.addEventListener("input", () => {
          slider.value = number.value;
          updateProcessorConfig();
        });
      }

      syncControls(pitchSlider, pitchNumber);
      syncControls(formantSlider, formantNumber);
      syncControls(wetSlider, wetNumber);

      function updateStatus(message, isError = false, isSuccess = false) {
        status.textContent = message;
        status.className = "status";
        if (isError) status.className += " error";
        if (isSuccess) status.className += " success";
        console.log(message);
      }

      function updateProcessorConfig() {
        if (workletNode) {
          const config = {
            pitchRatio: parseFloat(pitchNumber.value),
            formantRatio: parseFloat(formantNumber.value),
            dryWet: parseFloat(wetNumber.value),
          };
          workletNode.port.postMessage({
            command: "update-config",
            data: config,
          });
          console.log("Config updated:", config);
        }
      }

      async function startProcessing() {
        try {
          updateStatus("Initializing audio processing...");

          // Create audio context
          audioContext = new AudioContext({ sampleRate: 48000 });
          await audioContext.resume();

          // Get microphone access
          updateStatus("Requesting microphone access...");
          mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 48000,
              channelCount: 2,
              autoGainControl: false,
              echoCancellation: false,
              noiseSuppression: false,
            },
          });

          // Load AudioWorklet
          updateStatus("Loading pitch shift processor...");
          await audioContext.audioWorklet.addModule(
            "lib/processors/audio/pitch-shift-processor.js"
          );

          // Create worklet node
          workletNode = new AudioWorkletNode(
            audioContext,
            "pitch-shift-processor"
          );

          // Create microphone source
          micSource = audioContext.createMediaStreamSource(mediaStream);

          // Connect audio graph: microphone -> worklet -> speakers
          micSource.connect(workletNode);
          workletNode.connect(audioContext.destination);

          // Send initial configuration
          updateProcessorConfig();

          updateStatus(
            "üé§ Processing active! Speak into your microphone.",
            false,
            true
          );
          isProcessing = true;
          startBtn.disabled = true;
          stopBtn.disabled = false;
        } catch (error) {
          const errorMessage =
            error instanceof Error ? error.message : String(error);
          updateStatus(`‚ùå Error: ${errorMessage}`, true);
          stopProcessing();
        }
      }

      async function stopProcessing() {
        try {
          updateStatus("Stopping audio processing...");

          // Disconnect audio graph
          if (micSource) {
            micSource.disconnect();
            micSource = null;
          }

          if (workletNode) {
            workletNode.disconnect();
            workletNode = null;
          }

          // Stop media stream
          if (mediaStream) {
            mediaStream.getTracks().forEach((track) => track.stop());
            mediaStream = null;
          }

          // Close audio context
          if (audioContext) {
            await audioContext.close();
            audioContext = null;
          }

          updateStatus("‚èπÔ∏è Processing stopped", false, true);
          isProcessing = false;
          startBtn.disabled = false;
          stopBtn.disabled = true;
        } catch (error) {
          const errorMessage =
            error instanceof Error ? error.message : String(error);
          updateStatus(`‚ùå Error stopping: ${errorMessage}`, true);
        }
      }

      // Event listeners
      startBtn.addEventListener("click", startProcessing);
      stopBtn.addEventListener("click", stopProcessing);

      // Cleanup on page unload
      window.addEventListener("beforeunload", () => {
        if (isProcessing) {
          stopProcessing();
        }
      });

      updateStatus('Ready to start - Click "Start Processing" to begin');
    </script>
  </body>
</html>
